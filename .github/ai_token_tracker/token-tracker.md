# ğŸ¤– AI Token Tracker - Anleitung fÃ¼r KI

## ğŸ¯ Ãœberblick
Diese Anleitung erklÃ¤rt der KI, wie der AI Token Tracker optimal zu verwenden ist.

## ğŸ” Token-Status verstehen

### Status Bar Anzeige
```
[ğŸ¤– 45.2%] â† Live Token-Anzeige klicken fÃ¼r Details
```

### Tooltip-Information
- **Aktuelle Tokens**: z.B. 2,847 / 64,000
- **Auslastung**: Prozentuale Anzeige
- **AI-Modell**: Automatisch erkannt (GPT-4.1, GPT-4o, etc.)
- **Empfehlung**: NÃ¤chste Schritte

## ğŸš¦ Token-Ampel-System

### ğŸŸ¢ GrÃ¼n (0-50%): CONTINUE
- Normale Entwicklung mÃ¶glich
- Komplexe Refactorings erlaubt
- Umfassende Code-Generierung OK

### ğŸŸ¡ Gelb (50-75%): OPTIMIZE
- **Aktion**: PrÃ¤zisere Prompts verwenden
- **Strategie**: Weniger Kontext pro Request
- **Tipp**: Spezifische Fragen stellen

### ğŸŸ  Orange (75-90%): SPLIT
- **Sofort**: Aufgabe in Sub-Tasks aufteilen
- **Automatisch**: Neue Scopes erstellen
- **Empfehlung**: Chat-Split vorbereiten
- **Limit**: Nur essentielle Code-Ã„nderungen

### ğŸ”´ Rot (90%+): NEW_CHAT
- **SOFORT**: Neuen Chat starten
- **KRITISCH**: Halluzination-Gefahr!
- **Aktion**: Task-Liste erstellen
- **Stopp**: Keine groÃŸen Ã„nderungen mehr

## ğŸ—ï¸ Modularisierungs-Workflow

### Automatische Scope-Erstellung
Bei 75% Token-Auslastung:
1. **Analyse**: Aktuelle Aufgabe bewerten
2. **Split**: In logische Sub-Tasks aufteilen
3. **Struktur**: Neue Verzeichnisse erstellen:
   ```
   docs/ai_token_tracker/scopes_ad/
   â”œâ”€â”€ 01_current_task/
   â”œâ”€â”€ 02_sub_task_a/
   â”œâ”€â”€ 03_sub_task_b/
   â”œâ”€â”€ 04_tests/
   â””â”€â”€ 05_documentation/
   ```
4. **TODO**: Aufgabenliste generieren
5. **Focus**: Ersten Sub-Task starten

### Modularisierungs-Commands
```bash
# Modularisierungs-Workflow starten
Ctrl+Shift+P â†’ "AI Token Tracker: Projekt modularisieren"

# Scope-Management
Ctrl+Shift+P â†’ "AI Token Tracker: Neuen Scope erstellen"
```

## ğŸ“Š Brutto vs. Netto Tokens

### Token-Kette verstehen
- **Brutto-Tokens**: Alle Tokens im Chat (Verlauf + Anweisungen + Code)
- **Netto-Tokens**: VerfÃ¼gbare Tokens fÃ¼r neue Eingaben
- **Overhead**: ~20-30% fÃ¼r Chat-Verlauf und System-Prompts

### Break-Even Point Algorithmus
```typescript
// Intelligente Token-Berechnung
const nettoTokens = bruttoTokens * 0.7; // 30% Overhead
const complexityFactor = fileComplexity > 0.8 ? 0.6 : 0.8;
const effectiveLimit = nettoTokens * complexityFactor;

if (currentTokens > effectiveLimit) {
    // Chat-Split empfohlen
}
```

## ğŸ¯ SMART Prompt-Template

### FÃ¼r optimale Token-Nutzung:
```markdown
**Rolle**: [Spezifische Expertenrolle]
**Ziel**: [Konkretes, messbares Ziel]
**Kontext**: [Minimaler, relevanter Kontext]
**Aktion**: [Spezifische Aktion]
**Ergebnis**: [Erwartetes Format/Ergebnis]
**Constraints**: [Token-Limit, Zeit, Scope]
```

### Beispiel:
```markdown
**Rolle**: TypeScript Entwickler
**Ziel**: Token-Counter Klasse optimieren  
**Kontext**: AI Token Tracker Extension, tiktoken Library
**Aktion**: Refactor fÃ¼r bessere Performance
**Ergebnis**: Optimierte Klasse mit Tests
**Constraints**: Max 500 Tokens, fokus auf Core-Logik
```

## ğŸ”„ Automatische Integration

### Extension sendet automatisch:
- Token-Status nach jeder Ã„nderung
- Empfehlungen bei kritischen Limits
- Modell-Switching VorschlÃ¤ge
- Scope-Management Updates

### Chat-Nachrichten Format:
```
ğŸ¤– **AI Token Tracker - Automatische Konsolidierung**

ğŸ“Š **Aktuelle Token-Situation:**
â€¢ Datei: [filename]
â€¢ Tokens: [current] / [max]
â€¢ Auslastung: [percentage]%
â€¢ Modell: [model]

[ğŸŸ¢ğŸŸ¡ğŸŸ ğŸ”´] **Empfehlung:**
â€¢ Aktion: [CONTINUE|OPTIMIZE|SPLIT|NEW_CHAT]
â€¢ Grund: [specific reason]
â€¢ Dringlichkeit: [LOW|MEDIUM|HIGH|CRITICAL]
```

## ğŸ› ï¸ Troubleshooting

### HÃ¤ufige Szenarien:
1. **Token-Anzeige fehlt**: Extension aktiviert? Status Bar sichtbar?
2. **Falsche Limits**: Modell-Erkennung prÃ¼fen, manuell wechseln
3. **Zu viele Nachrichten**: Rate-Limiting anpassen
4. **Chat-Integration**: Fallback-Methoden werden automatisch probiert

### Quick-Fixes:
```bash
# Extension neu laden
Ctrl+Shift+P â†’ "Developer: Reload Window"

# Manuelle Token-Berechnung
Ctrl+Shift+P â†’ "AI Token Tracker: Manuelle Konsolidierung"
```

---

## ğŸ¯ Fazit fÃ¼r KI

**Verwende immer:**
1. âœ… Token-Status vor groÃŸen Ã„nderungen prÃ¼fen
2. âœ… Bei 75%+ automatisch Aufgaben splitten  
3. âœ… SMART-Prompts fÃ¼r optimale Token-Nutzung
4. âœ… Scope-basierte Modularisierung befolgen
5. âœ… Bei 90%+ sofort neuen Chat starten

**Die Extension unterstÃ¼tzt dich automatisch - vertraue den Empfehlungen!** ğŸš€
